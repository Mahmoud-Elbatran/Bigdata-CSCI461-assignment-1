##### ASSIGNMENT REQUIREMENTS: #####

- Start by creating a directory on your local machine named bd-a1/.
- Download and place the dataset in the bd-a1/ directory [Choose any simple dataset from
the web].
- Inside the bd-a1/ directory, create a Dockerfile does the following:
- Specify the base image as Ubuntu. [0.5 MARK]
- Install the following packages in the Dockerfile: Python3, Pandas, Numpy,
Seaborn, Matplotlib, scikit-learn, and Scipy. [1 MARK]
- Create a directory inside the container at /home/doc-bd-a1/. [0.5 MARK]
- Move the dataset file to the container. [0.5 MARK]
- Open the bash shell upon container startup. [0.5 MARK]
- Note: Install any additional modules or libraries you anticipate needing within the
container.


- Within the container's doc-bd-a1/ directory (after having the image and having a running
container), create the following files:

- load.py: Design this file to dynamically read the dataset file by accepting the file
path as a user-provided argument. [0.5 MARK]
- dpre.py: This file should perform Data Cleaning, Data Transformation, Data
Reduction, and Data Discretization steps. In each step apply minimum 2 tasks.
Save the resulting data frame as a new CSV file named res_dpre.csv. [2
MARKS]
- eda.py: Conduct exploratory data analysis, generating at least 3 insights without
visualizations. Save these insights as text files named eda-in-1.txt, eda-in-2.txt,
and so on. [1 MARK]
- vis.py: Create a single visualization and save it as vis.png. [0.5 MARK]
- model.py: Implement the K-means algorithm on your data with the columns you
deem suitable for K-means, setting k=3. Save the number of records in each
cluster as a text file named k.txt. [1 MARK]
- final.sh: Compose a simple bash script on your local machine to copy the output
files generated by dpre.py, eda.py, vis.py, and model.py from the container to
your local machine in bd-a1/service-result/. Finally, the script should stop the
container. [1 MARK]


# Notes:

● Each Python file responsible for updating the data frame should invoke the next Python
file and transmit the data frame path to it. Subsequently, read the CSV file as a data frame
and continue processing.
● To execute your project, perform the following steps:
○ After creating the Dockerfile, build it to produce an image.
○ Run the container using the generated image.
○ Inside the container, create the Python files as specified.
○ Initiate the pipeline using the command (inside the container): python3 load.py
<dataset-path>.
○ The pipeline will generate several files and figures, conforming to the prescribed
outputs. These will be relocated from the container to your local machine in
bd-a1/service-result/ using the bash script.
○ README file showing the execution of the project, all Docker commands used,
etc. [1 MARK]


# BONUS:

● Push the Docker Image to Docker Hub. [0.5 MARK]
● Push all your files to a GitHub repo. [0.5 MARK]

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

# * `FROM` keyword indicates that you are specifying the base image.
# * `ubuntu` is the name of the base image you're using.
# * `:latest` is a tag that refers to the latest version of the Ubuntu image available on Docker Hub. This ensures that you're using the most recent version of Ubuntu for your container.
# Specify the base image as Ubuntu
FROM ubuntu:latest


# * `apt-get update` ensures that the package lists for Ubuntu are updated to the latest version.
# * `apt-get install -y python3 python3-pip` installs Python3 and pip3 package manager for Python3.
# * `pip3 install pandas numpy seaborn matplotlib scikit-learn scipy` installs the specified Python packages using pip3.
# Each package is installed in a single `pip3 install` command to minimize the number of layers created in the Docker image, which helps keep the image size smaller.
# Install necessary packages
RUN apt-get update && \
    apt-get install -y python3 python3-pip && \
    pip3 install pandas numpy seaborn matplotlib scikit-learn scipy



# `mkdir -p /home/doc-bd-a1/` is the command that creates a directory named `doc-bd-a1` inside the `/home/` directory of the container. 
#  The `-p` flag is used to create parent directories as needed, ensuring that the command does not fail if the `/home/` directory does not exist.
# Create a directory inside the container
RUN mkdir -p /home/doc-bd-a1/    


# this code will copy the `disney_movies.csv` file from local directory into the `/home/doc-bd-a1/` directory inside the container.
# Move the dataset file to the container
COPY disney_movies.csv /home/doc-bd-a1/


# the `CMD` instruction is used to specify the command that should be executed when a container starts.
# * `CMD ["/bin/bash"]` specifies that when the container starts, it should execute the command `/bin/bash` is the location of the Bash shell interpreter on most Linux-based systems., which opens a bash shell.
# Include this line at the end of your Dockerfile. This way, when you run your container, it will start the bash shell, allowing you to interact with the container's command line.
# Open bash shell upon container startup
CMD ["/bin/bash"]





##### Build Docker Image #####
# Build Docker Image: Open your terminal or command prompt, navigate to the directory where your Dockerfile is located (bd-a1/ directory), and execute the following command:

# The command `docker build -t bd_a1_image .` is used to build a Docker image based on the Dockerfile located in the current directory (`.`). Let's break down this command:
# * `docker build`: This command is used to build Docker images from a Dockerfile.
# * `-t bd_a1_image`: The (`-t`) flag is used to specify a tag for the image being built. In this case, the tag is `bd_a1_image`. Tags are used to label and identify different versions of an image.
# * `.`: The dot (`.`) at the end of the command specifies the build context. This tells Docker to look for the Dockerfile and any other necessary files in the current directory.

# When we run this command in our terminal or command prompt, Docker will start the build process using the Dockerfile in the current directory. 
# It will execute each instruction in the Dockerfile, such as installing packages and copying files, to create a Docker image. 
# Once the build process is complete, you will have a Docker image tagged as `my_bd_a1_image`, which you can then use to run containers.

docker build -t bd_a1_image .

##### Run Docker Container #####
# Run Docker Container: After successfully building the Docker image, you can run a container based on that image using the following command:
    
    
# `-it` flag allows you to interact with the container using a terminal session.
# `--name my_bd_a1_container` gives a name (`my_bd_a1_container`) to your running container.
# `bd_a1_image` is the name of the Docker image you want to run a container from.

docker run -it --name my_bd_a1_container bd_a1_image


##### Explore the Container #####
# Explore the Container: Once the container starts, you'll be dropped into a Bash shell prompt inside the container. You can navigate to the `/home/doc-bd-a1/` directory using `cd /home/doc-bd-a1/` command and verify that the `disney_movies.csv` file has been successfully copied into this directory.
# You can also verify that Python and the required libraries are installed by running commands like `python3 --version` and `pip3 list`.